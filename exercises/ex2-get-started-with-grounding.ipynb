{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"5001f602\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Exercise 2 - Get Started with Grounding\\n\",\n",
    "    \"\\n\",\n",
    "    \"In this exercise, we'll start exploring the grounding on SAP AI Core. Grounding allows Large Language Models (LLMs) to reference specific knowledge sources when generating responses, which can help improve accuracy and relevance. \\n\",\n",
    "    \"\\n\",\n",
    "    \"We'll start with the basics by grounding an LLM using SAP.help as our knowledge source. \\n\",\n",
    "    \"\\n\",\n",
    "    \"This exercise will cover:\\n\",\n",
    "    \"\\n\",\n",
    "    \"* Basic grounding concepts in SAP AI Core\\n\",\n",
    "    \"* How to set up grounding with a sap.help.com\\n\",\n",
    "    \"* Comparing responses with and without grounding\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"f306eb73\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Check your connection to AI Core \\n\",\n",
    "    \"üëÄ  In the ```TECHE2025-167/excercise/init_env.py``` the values from ```TECHED2025-AI167/.aicore-config.json``` are assigned to environment variables. That way the **SAP Cloud SDK for AI(Python)** will connect to AI Core.\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Add orchestration deployment URL to variables.py\\n\",\n",
    "    \"\\n\",\n",
    "    \"üëÄ  Before we can getstarted, one final step is missing. You need to change the value assigned to the **AICORE_ORCHESTRATION_DEPLOYMENT_URL** in the ```variables.py``` to your own orchestration deployment URL.\\n\",\n",
    "    \"Therefore run the below code and copy the URL and add into the variables.py add the respective place.\\n\",\n",
    "    \"\\n\",\n",
    "    \"TODO: image below does not show up when viewing the notebook on github.com.\\n\",\n",
    "    \"\\n\",\n",
    "    \"TODO: images below have different size.\\n\",\n",
    "    \"\\n\",\n",
    "    \"<p>\\n\",\n",
    "    \"<img src=\\\"images/deployment_url.png\\\" alt=\\\"Visual Studio Code\\\" width=\\\"600\\\"/>\\n\",\n",
    "    \"</p>\\n\",\n",
    "    \"\\n\",\n",
    "    \"![Deployment URL screenshot](images/deployment_url.png)\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"id\": \"96a0ead3\",\n",
    "   \"metadata\": {\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-10-26T11:28:31.928190Z\",\n",
    "     \"start_time\": \"2025-10-26T11:28:31.823203Z\"\n",
    "    }\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"import init_env\\n\",\n",
    "    \"import helpers\\n\",\n",
    "    \"\\n\",\n",
    "    \"\\n\",\n",
    "    \"init_env.set_environment_variables()\\n\",\n",
    "    \"\\n\",\n",
    "    \"url = helpers.extract_deployment_url()\\n\",\n",
    "    \"print(url)\"\n",
    "   ],\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"ename\": \"ModuleNotFoundError\",\n",
    "     \"evalue\": \"No module named 'ai_core_sdk'\",\n",
    "     \"output_type\": \"error\",\n",
    "     \"traceback\": [\n",
    "      \"\\u001B[31m---------------------------------------------------------------------------\\u001B[39m\",\n",
    "      \"\\u001B[31mModuleNotFoundError\\u001B[39m                       Traceback (most recent call last)\",\n",
    "      \"\\u001B[36mCell\\u001B[39m\\u001B[36m \\u001B[39m\\u001B[32mIn[1]\\u001B[39m\\u001B[32m, line 2\\u001B[39m\\n\\u001B[32m      1\\u001B[39m \\u001B[38;5;28;01mimport\\u001B[39;00m\\u001B[38;5;250m \\u001B[39m\\u001B[34;01minit_env\\u001B[39;00m\\n\\u001B[32m----> \\u001B[39m\\u001B[32m2\\u001B[39m \\u001B[38;5;28;01mimport\\u001B[39;00m\\u001B[38;5;250m \\u001B[39m\\u001B[34;01mhelpers\\u001B[39;00m\\n\\u001B[32m      5\\u001B[39m init_env.set_environment_variables()\\n\\u001B[32m      7\\u001B[39m url = helpers.extract_deployment_url()\\n\",\n",
    "      \"\\u001B[36mFile \\u001B[39m\\u001B[32m~/SAPDevelop/github.com/SAP-Samples/teched2025-AI167/exercises/helpers.py:3\\u001B[39m\\n\\u001B[32m      2\\u001B[39m \\u001B[38;5;28;01mimport\\u001B[39;00m\\u001B[38;5;250m \\u001B[39m\\u001B[34;01mos\\u001B[39;00m,\\u001B[38;5;250m \\u001B[39m\\u001B[34;01mjson\\u001B[39;00m\\n\\u001B[32m----> \\u001B[39m\\u001B[32m3\\u001B[39m \\u001B[38;5;28;01mfrom\\u001B[39;00m\\u001B[38;5;250m \\u001B[39m\\u001B[34;01mai_core_sdk\\u001B[39;00m\\u001B[34;01m.\\u001B[39;00m\\u001B[34;01mai_core_v2_client\\u001B[39;00m\\u001B[38;5;250m \\u001B[39m\\u001B[38;5;28;01mimport\\u001B[39;00m AICoreV2Client\\n\\u001B[32m      4\\u001B[39m \\u001B[38;5;28;01mimport\\u001B[39;00m\\u001B[38;5;250m \\u001B[39m\\u001B[34;01mrequests\\u001B[39;00m\\n\\u001B[32m      5\\u001B[39m \\u001B[38;5;28;01mimport\\u001B[39;00m\\u001B[38;5;250m \\u001B[39m\\u001B[34;01mvariables\\u001B[39;00m\\n\",\n",
    "      \"\\u001B[31mModuleNotFoundError\\u001B[39m: No module named 'ai_core_sdk'\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 1\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"99cd8a9e\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"‚û°Ô∏è Restart the Juypyter Kernel\\n\",\n",
    "    \"\\n\",\n",
    "    \"<p>\\n\",\n",
    "    \"<img src=\\\"images/restart_kernel.png\\\" alt=\\\"Visual Studio Code\\\" width=\\\"800\\\"/>\\n\",\n",
    "    \"</p>\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"c34dd979\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import init_env\\n\",\n",
    "    \"import variables\\n\",\n",
    "    \"# Run this to test whether all environment variables are set correctly \\n\",\n",
    "    \"init_env.set_environment_variables()\\n\",\n",
    "    \"\\n\",\n",
    "    \"assert variables.AICORE_ORCHESTRATION_DEPLOYMENT_URL!='', \\\"\\\"\\\"You should change the value assigned to the `AICORE_ORCHESTRATION_DEPLOYMENT_URL` in the `variables.py` file to your own resource group first!\\\"\\\"\\\"\\n\",\n",
    "    \"print(f\\\"Deployment URL is set to: {variables.AICORE_ORCHESTRATION_DEPLOYMENT_URL}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"c8f0fbf8\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"> \\n\",\n",
    "    \"> ‚ú® **More information: Orchestration Service**  \\n\",\n",
    "    \"> \\n\",\n",
    "    \">The orchestration service of Generative AI Hub lets you use all the available models with the same codebase. You only deploy the orchestration service and then you can access all available models simply by changing the model name parameter.   \\n\",\n",
    "    \">You can also use grounding, prompt templating, data masking and content filtering capabilities.  \\n\",\n",
    "    \">In the following we are mainly using it for grounding\\n\",\n",
    "    \"\\n\",\n",
    "    \"TODO: add link to orchestration documentation?\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"9dee4502\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Let's start with a simple prompt\\n\",\n",
    "    \"\\n\",\n",
    "    \"To understand the general idea about grounding a model, let us first start with the simple prompt without grounding it. \"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"ff37cf8a\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Import the packages we want to use \"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"a2c55109\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from gen_ai_hub.orchestration.models.llm import LLM\\n\",\n",
    "    \"from gen_ai_hub.orchestration.models.config import OrchestrationConfig\\n\",\n",
    "    \"from gen_ai_hub.orchestration.models.template import Template, TemplateValue\\n\",\n",
    "    \"from gen_ai_hub.orchestration.models.message import SystemMessage, UserMessage\\n\",\n",
    "    \"from gen_ai_hub.orchestration.service import OrchestrationService\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"fb9d1b15\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Assign the model we want to use \"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"6140cd8e\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"llm = LLM(\\n\",\n",
    "    \"    name=\\\"gemini-2.5-flash\\\",\\n\",\n",
    "    \"    parameters={\\n\",\n",
    "    \"        'temperature': 0.0,\\n\",\n",
    "    \"    }\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"f94265bc\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Create a prompt Template\\n\",\n",
    "    \"The parameter user_query in the code snippet below is going to hold the user query that you will add later on. \"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"eade6cde\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"template = Template(\\n\",\n",
    "    \"            messages=[\\n\",\n",
    "    \"                SystemMessage(\\\"You are a helpful assistant.\\\"),\\n\",\n",
    "    \"                UserMessage(\\\"\\\"\\\"Answer the request by providing relevant answers that fit to the request.\\n\",\n",
    "    \"                Request: {{ ?user_query }}\\n\",\n",
    "    \"                \\\"\\\"\\\"),\\n\",\n",
    "    \"            ]\\n\",\n",
    "    \"        )\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"71fe68a1\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Create an orchestration configuration\\n\",\n",
    "    \"Next you need to create the orchestration configuration by including the LLM we referenced and the prompt template we just created.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"c6240964\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"config = OrchestrationConfig(\\n\",\n",
    "    \"    template=template,\\n\",\n",
    "    \"    llm=llm,\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"85da235d\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Execute the query\\n\",\n",
    "    \"This configuration we now add to the OrchestrationService and then we run to retrieve the answer. \"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"a402f789\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import importlib\\n\",\n",
    "    \"variables = importlib.reload(variables)\\n\",\n",
    "    \"\\n\",\n",
    "    \"orchestration_service = OrchestrationService(\\n\",\n",
    "    \"    api_url=variables.AICORE_ORCHESTRATION_DEPLOYMENT_URL,\\n\",\n",
    "    \"    config=config,\\n\",\n",
    "    \")\\n\",\n",
    "    \"result = orchestration_service.run(\\n\",\n",
    "    \"    template_values=[\\n\",\n",
    "    \"        TemplateValue(\\n\",\n",
    "    \"            name=\\\"user_query\\\",\\n\",\n",
    "    \"            #TODO Here you can change the user prompt into whatever you want to ask the model\\n\",\n",
    "    \"            value=\\\"What is Joule?\\\"\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"    ]\\n\",\n",
    "    \")\\n\",\n",
    "    \"print(result.orchestration_result.choices[0].message.content)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"699b4a52\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Looks correct, but not for our context\\n\",\n",
    "    \"\\n\",\n",
    "    \"The model‚Äôs answer to ‚ÄúWhat is Joule?‚Äù is *technically* correct because, without any extra context, it defaults to the statistically most common public meaning (the physics unit of energy). Our expectation at SAP TechEd was an SAP‚Äëspecific interpretation (e.g., an SAP capability or product named ‚ÄúJoule‚Äù), but the prompt contained no SAP signals, product names, or retrieved SAP documents to steer the model. With no domain clues, the generic global prior wins.  \\n\",\n",
    "    \"\\n\",\n",
    "    \"Grounding can solve this: attach a grounding/data-retrieval step (SAP Help, internal docs, knowledge base) and inject them into the prompt (or pipeline) before generation. \\n\",\n",
    "    \"In short: no context ‚Üí generic answer; grounded context ‚Üí domain‚Äëspecific answer.\\n\",\n",
    "    \"\\n\",\n",
    "    \"üí™  Let's do this. \"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"3ec8fcb3\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Ground your prompt with SAP Help\\n\",\n",
    "    \"\\n\",\n",
    "    \"To add context to the retrieval step we need to some change to our original steps. \\n\",\n",
    "    \"\\n\",\n",
    "    \"Starting at the template by adding to the UserMessage ```Context:{{ ?grounding_response }}```. Whereas **grounding_response** is the context retrieved from the context information, in this case sap.help.com.\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"bf17b658\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"\\n\",\n",
    "    \"template = Template(\\n\",\n",
    "    \"            messages=[\\n\",\n",
    "    \"                SystemMessage(\\\"You are a helpful assistant.\\\"),\\n\",\n",
    "    \"                UserMessage(\\\"\\\"\\\"Answer the request by providing relevant answers that fit to the request.\\n\",\n",
    "    \"                Request: {{ ?user_query }}\\n\",\n",
    "    \"                Context:{{ ?grounding_response }}\\n\",\n",
    "    \"                \\\"\\\"\\\"),\\n\",\n",
    "    \"            ]\\n\",\n",
    "    \"        )\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"604a46eb\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Import the packages we want to use \"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"ab322589\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"\\n\",\n",
    "    \"from gen_ai_hub.orchestration.models.document_grounding import DocumentGroundingFilter\\n\",\n",
    "    \"from gen_ai_hub.orchestration.models.document_grounding import GroundingModule\\n\",\n",
    "    \"from gen_ai_hub.orchestration.models.document_grounding import GroundingType\\n\",\n",
    "    \"from gen_ai_hub.orchestration.models.document_grounding import DocumentGrounding\\n\",\n",
    "    \"from gen_ai_hub.orchestration.models.document_grounding import DataRepositoryType\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"2f212319\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Define data repository \\n\",\n",
    "    \"We need to configure the Grounding Module, where we first define the data repository that we want to use via the **filter** parameter. \\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"4cee90de\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"\\n\",\n",
    "    \"filters = [\\n\",\n",
    "    \"            DocumentGroundingFilter(    id=\\\"SAPHelp\\\", \\n\",\n",
    "    \"                                        data_repository_type=DataRepositoryType.URL.value) # replace <data_repository_type> by \\\"help.sap.com\\\"\\n\",\n",
    "    \"        ]\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"517c16e5\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Create Grounding Configuration\\n\",\n",
    "    \"Next we create the grounding configuration by using **GroundingModule** for managing and applying grounding configurations:  \\n\",\n",
    "    \"- **type**: \\\"document_grounding_service\\\"\\n\",\n",
    "    \"- **config**:  Configuration dictionary including parameter defined in the template and filter that includes the data repository type\\n\",\n",
    "    \"\\n\",\n",
    "    \"TODO: explain in more detail how input_params and output_param correspond to the template, and overall \\\"pipeline\\\" architecture of Orchestration Service?\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"a8cfdc1c\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"\\n\",\n",
    "    \"grounding_config = GroundingModule(\\n\",\n",
    "    \"            type=GroundingType.DOCUMENT_GROUNDING_SERVICE.value,\\n\",\n",
    "    \"            config=DocumentGrounding(input_params=[\\\"user_query\\\"], output_param=\\\"grounding_response\\\", filters=filters)\\n\",\n",
    "    \"        )\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"fe8d9cc4\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Create Orchestration Configuration \\n\",\n",
    "    \"\\n\",\n",
    "    \"Grounding configuration ```grounding_config``` is now an additional parameter that we add to the Orchestration configuration. \"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"9e9e82e2\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"\\n\",\n",
    "    \"config = OrchestrationConfig(\\n\",\n",
    "    \"    template=template,\\n\",\n",
    "    \"    llm=llm,\\n\",\n",
    "    \"    grounding=grounding_config\\n\",\n",
    "    \")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"74948dc3\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Execute the  Query\\n\",\n",
    "    \"Configuration will be added again to the OrchestrationService and then we run to retrieve the answer.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"57564d83\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import importlib\\n\",\n",
    "    \"variables = importlib.reload(variables)\\n\",\n",
    "    \"\\n\",\n",
    "    \"orchestration_service = OrchestrationService(\\n\",\n",
    "    \"    api_url=variables.AICORE_ORCHESTRATION_DEPLOYMENT_URL,\\n\",\n",
    "    \"    config=config\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"response = orchestration_service.run(\\n\",\n",
    "    \"    template_values=[\\n\",\n",
    "    \"        TemplateValue( \\n\",\n",
    "    \"            name=\\\"user_query\\\",\\n\",\n",
    "    \"            value=\\\"What is Joule?\\\"\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"    ]\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(response.orchestration_result.choices[0].message.content)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"metadata\": {},\n",
    "   \"cell_type\": \"code\",\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": null,\n",
    "   \"source\": [\n",
    "    \"# TODO: show the internally used grounding result?\\n\",\n",
    "    \"print( response.module_results.grounding.data[\\\"grounding_result\\\"][:120] )\"\n",
    "   ],\n",
    "   \"id\": \"7bf38ab98ad593b3\"\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"78e18b87\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### The right context\\n\",\n",
    "    \"Grounding succeeded: with help.sap.com context injected, the model produced the correct SAP‚Äëspecific answer.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"a90482d6\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Summary \\n\",\n",
    "    \"You learned the basic grounding concepts in SAP AI Core and how you to use it improve the retrieval.\\n\",\n",
    "    \"\\n\",\n",
    "    \"In the next exercise you will learn on how to ingest custom documents.\\n\",\n",
    "    \"\\n\",\n",
    "    \"TODO: at this point, I will be working in Visual Studio Code - should we prompt attendees to go back to GitHub?\\n\",\n",
    "    \"In VS Code, the markdown will not look good unless we ask attendes to enable the markdown rendering.\\n\",\n",
    "    \"\\n\",\n",
    "    \"Continue to - [Exercise 3: Ground your LLM with custom documents](ex3-1-grounding-vector-api.md)\\n\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"ai167env\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.11.9\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ],
   "id": "9c5aff4e18b2b458"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai167env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
